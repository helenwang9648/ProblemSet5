{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 - Accessing data sets using Python\n",
    "_Complete the following Python tasks. Comments aren't required but they can be helpful in awarding partial credit if you fail to get the correct answer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Reading local files into Python\n",
    "* Reference:  `00-Importing-Local-Files.ipynb` in the `GettingData` repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1a: Importing a local csv file using base Python\n",
    "Read the contents of the tab-delimited file `SaraTheTurtle.txt` (located in the data folder) into a list of line items such that you can easily retrieve values in specific rows and columns. Use either Python's file object or the built-in csv module. \n",
    "\n",
    "_If you have trouble with the tab-delimited file, try using the comma-delimited version `SaraTheTurtle.csv`, though this will cost you a penalty._\n",
    "\n",
    "Then report the value in the **10th row** (*excluding* the header data, i.e. the 11th row of the file) and **6th column**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file into a list of line items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the value in the 10th row, 6th column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b: Import using Numpy\n",
    "Read in the same dataset, but this time using the Numpy package to read the data into a Numpy array, skipping the header row. \n",
    "\n",
    "Reveal the item in the 10th row, 6th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file into a Numpy array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the value in the 10th row, 6th column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1c: Import using Pandas\n",
    "Read in the same dataset, but this time using the Numpy package to read the data into a Numpy array, skipping the header row. \n",
    "\n",
    "Reveal the item in the 10th row, 6th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file into Pandas dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the value in the 10th row, 6th column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2. Reading remote text files into Python (using Pandas)\n",
    "* Reference: `01a-Getting-data-with-Pandas.ipynb` in the `GettingData` repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2a. Import NWIS discharge data located at a web address:\n",
    "Using Pandas, read the data located at the URL below into a dataframe:\n",
    "http://waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&period=1&begin_date=&end_date=&site_no=02085070. \n",
    "\n",
    "â†’ Be sure to omit metadata lines (those that begin with \"#\" and the data format line just below the header line. (This is just as we did in the class exercise...) \n",
    "\n",
    "Finally, display the first 5 rows in this dataframe using the pandas `head()` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the remote data into a pandas dataframe, ommitting commented lines in the input file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first row in the dataframe as it contains metadata, not data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show the first 5 records of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b. Saving a dataframe to a local csv file\n",
    "Save your dataframe to a csv file named `NWISDischarge.csv` in your data folder. (You may opt to keep the index column in your output file or not...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the file to a local csv\n",
    "dfNWIS.to_csv('./data/NWISDischarge.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Bulk data download using `urllib`\n",
    "The FTP folder [ftp://rockyftp.cr.usgs.gov/vdelivery/Datasets/Staged/LndCvr/Shape/](https://bit.ly/2PWFlOS) contains land cover shapes for all US states. Use the example covered in class to write code that downloads, unzips, and displays land cover for **Hawaii**.\n",
    "* Reference: `02b-Extract-Statewide-HUCs-with-urllib.ipynb` in the `GettingData` repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
